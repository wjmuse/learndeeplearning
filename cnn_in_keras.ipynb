{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import math\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create function to read CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "def ndarray2image (arr_data, image_fn):\n",
    "\timsave(image_fn, arr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set dataset path\n",
    "dataset_path = '../cnn/cifar_10/'\n",
    "# define the information of images which can be obtained from official website\n",
    "height, width, dim = 32, 32, 3\n",
    "classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_batch_1\n",
      "<type 'dict'>\n",
      "(10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "''' read training data '''\n",
    "# get the file names which start with \"data_batch\" (training data)\n",
    "train_fns = [fn for fn in listdir(dataset_path) if isfile(join(dataset_path, fn)) & fn.startswith(\"data_batch\")]\n",
    "# list sorting\n",
    "train_fns.sort()\n",
    "# make a glace about the training data\n",
    "fn = train_fns[0]\n",
    "print fn\n",
    "raw_data = unpickle(dataset_path + fn)\n",
    "print type(raw_data)\n",
    "raw_data_keys = raw_data.keys()\n",
    "print raw_data['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training data \n",
    "\n",
    "`train_fns[0:3]` means only read the first three part, because the training time is to long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate pixel (px) data into one ndarray [img_px_values]\n",
    "# concatenate label data into one ndarray [img_lab]\n",
    "img_px_values = 0\n",
    "img_lab = 0\n",
    "for fn in train_fns[0:3]:\n",
    "    raw_data = unpickle(dataset_path + fn)\n",
    "    if fn == train_fns[0]:\n",
    "        img_px_values = raw_data['data']\n",
    "        img_lab = raw_data['labels']\n",
    "    else:\n",
    "        img_px_values = numpy.vstack((img_px_values, raw_data['data']))\n",
    "        img_lab = numpy.hstack((img_lab, raw_data['labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer data to training foramt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (30000, 32, 32, 3)\n",
      "Y_train shape: (30000, 10)\n"
     ]
    }
   ],
   "source": [
    "# convert 1d-ndarray (0:3072) to 3d-ndarray(32,32,3)\n",
    "X_train = numpy.asarray([numpy.dstack((r[0:(width*height)].reshape(height,width),\n",
    "\t\t\t\t\t\t\t\t\t   r[(width*height):(2*width*height)].reshape(height,width),\n",
    "\t\t\t\t\t\t\t\t\t   r[(2*width*height):(3*width*height)].reshape(height,width)\n",
    "\t\t\t\t\t\t\t\t\t )) for r in img_px_values])\n",
    "\n",
    "Y_train = np_utils.to_categorical(numpy.array(img_lab), classes)\n",
    "\n",
    "# check is same or not!\n",
    "# lab_eql = numpy.array_equal([(numpy.argmax(r)) for r in Y_train], numpy.array(img_lab))\n",
    "\n",
    "# draw one image from the pixel data\n",
    "ndarray2image(X_train[0],\"test_image.png\")\n",
    "\n",
    "\n",
    "print 'X_train shape:', X_train.shape\n",
    "print 'Y_train shape:', Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print image to check format accurcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJZElEQVR4nAXB2Y8dWX0A4LP8TtWp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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename='test_image.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n",
      "dim(data) (10000, 3072)\n",
      "dim(labels) (10000,)\n"
     ]
    }
   ],
   "source": [
    "test_fns = [fn for fn in listdir(dataset_path) if isfile(join(dataset_path, fn)) & fn.startswith(\"test_batch\")]\n",
    "\n",
    "# read testing data\n",
    "raw_data = unpickle(dataset_path + fn)\n",
    "\n",
    "# type of raw data\n",
    "print type(raw_data)\n",
    "\n",
    "# check keys of testing data\n",
    "raw_data_keys = raw_data.keys()\n",
    "# ['data', 'labels', 'batch_label', 'filenames']\n",
    "\n",
    "img_px_values = raw_data['data']\n",
    "\n",
    "# check dimensions of data\n",
    "print \"dim(data)\", numpy.array(img_px_values).shape\n",
    "\n",
    "img_lab = raw_data['labels']\n",
    "# check dimensions of labels\n",
    "print \"dim(labels)\",numpy.array(img_lab).shape\n",
    "# dim(data) (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = numpy.asarray([numpy.dstack((r[0:(width*height)].reshape(height,width),\n",
    "\t\t\t\t\t\t\t\t\t  r[(width*height):(2*width*height)].reshape(height,width),\n",
    "\t\t\t\t\t\t\t\t\t  r[(2*width*height):(3*width*height)].reshape(height,width)\n",
    "\t\t\t\t\t\t\t\t\t)) for r in img_px_values])\n",
    "\n",
    "Y_test = np_utils.to_categorical(numpy.array(raw_data['labels']), classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale image data to range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "# print the dimension of training data\n",
    "print 'X_test shape:', X_test.shape\n",
    "print 'Y_test shape:', Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''CNN model'''\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=X_train[0].shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "learning_decay = 0.01/32\n",
    "sgd = SGD(lr=learning_rate, decay=learning_decay, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 32, 32)    896         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 32, 32, 32)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 30, 30, 32)    9248        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 30, 30, 32)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 15, 15, 32)    0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 15, 15, 32)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 7200)          0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 512)           3686912     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 512)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 512)           0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 10)            5130        dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 10)            0           dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3702186\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' training'''\n",
    "batch_size = 128\n",
    "epoch = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/16\n",
      "30000/30000 [==============================] - 143s - loss: 2.0316 - acc: 0.2527 - val_loss: 1.7414 - val_acc: 0.3976\n",
      "Epoch 2/16\n",
      "30000/30000 [==============================] - 142s - loss: 1.6912 - acc: 0.3964 - val_loss: 1.5101 - val_acc: 0.4667\n",
      "Epoch 3/16\n",
      "30000/30000 [==============================] - 146s - loss: 1.5136 - acc: 0.4538 - val_loss: 1.3919 - val_acc: 0.5023\n",
      "Epoch 4/16\n",
      "30000/30000 [==============================] - 138s - loss: 1.3940 - acc: 0.5007 - val_loss: 1.3125 - val_acc: 0.5401\n",
      "Epoch 5/16\n",
      "30000/30000 [==============================] - 132s - loss: 1.2957 - acc: 0.5344 - val_loss: 1.2372 - val_acc: 0.5572\n",
      "Epoch 6/16\n",
      "30000/30000 [==============================] - 139s - loss: 1.2279 - acc: 0.5582 - val_loss: 1.1972 - val_acc: 0.5763\n",
      "Epoch 7/16\n",
      "30000/30000 [==============================] - 144s - loss: 1.1552 - acc: 0.5869 - val_loss: 1.1444 - val_acc: 0.5936\n",
      "Epoch 8/16\n",
      "30000/30000 [==============================] - 148s - loss: 1.1033 - acc: 0.6063 - val_loss: 1.1355 - val_acc: 0.5971\n",
      "Epoch 9/16\n",
      "30000/30000 [==============================] - 139s - loss: 1.0477 - acc: 0.6245 - val_loss: 1.0980 - val_acc: 0.6101\n",
      "Epoch 10/16\n",
      "30000/30000 [==============================] - 142s - loss: 1.0009 - acc: 0.6457 - val_loss: 1.0745 - val_acc: 0.6224\n",
      "Epoch 11/16\n",
      "30000/30000 [==============================] - 143s - loss: 0.9496 - acc: 0.6624 - val_loss: 1.0416 - val_acc: 0.6324\n",
      "Epoch 12/16\n",
      "30000/30000 [==============================] - 138s - loss: 0.9079 - acc: 0.6774 - val_loss: 1.0205 - val_acc: 0.6425\n",
      "Epoch 13/16\n",
      "30000/30000 [==============================] - 153s - loss: 0.8675 - acc: 0.6952 - val_loss: 1.0120 - val_acc: 0.6472\n",
      "Epoch 14/16\n",
      "30000/30000 [==============================] - 138s - loss: 0.8231 - acc: 0.7073 - val_loss: 1.0058 - val_acc: 0.6518\n",
      "Epoch 15/16\n",
      "30000/30000 [==============================] - 136s - loss: 0.7852 - acc: 0.7213 - val_loss: 0.9998 - val_acc: 0.6534\n",
      "Epoch 16/16\n",
      "30000/30000 [==============================] - 144s - loss: 0.7513 - acc: 0.7323 - val_loss: 0.9992 - val_acc: 0.6517\n"
     ]
    }
   ],
   "source": [
    "# validation data comes from testing data\n",
    "fit_log = model.fit(X_train, Y_train, batch_size=batch_size,\n",
    "\t                nb_epoch=epoch, validation_data=(X_test, Y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model & save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''saving training history'''\n",
    "import csv\n",
    "history_fn = 'M3_cp32_3_cp32_3_m_d512.csv'\n",
    "with open(history_fn, 'wb') as csv_file:\n",
    "\tw = csv.writer(csv_file)\n",
    "\ttemp = numpy.array(fit_log.history.values())\n",
    "\tw.writerow(fit_log.history.keys())\n",
    "\tfor i in range(temp.shape[1]):\n",
    "\t\tw.writerow(temp[:,i])\n",
    "\n",
    "'''saving model'''\n",
    "from keras.models import load_model\n",
    "model.save('M3_cp32_3_cp32_3_m_d512.h5')\n",
    "del model\n",
    "\n",
    "'''loading model'''\n",
    "model = load_model('M3_cp32_3_cp32_3_m_d512.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rate: 0.6517\n"
     ]
    }
   ],
   "source": [
    "'''prediction'''\n",
    "pred = model.predict_classes(X_test, batch_size, verbose=0)\n",
    "ans = [numpy.argmax(r) for r in Y_test]\n",
    "\n",
    "# caculate accuracy rate of testing data\n",
    "acc_rate = sum(pred-ans == 0)/float(pred.shape[0])\n",
    "\n",
    "print \"Accuracy rate:\", acc_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
